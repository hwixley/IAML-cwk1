\BOOKMARK [1][-]{section.1}{: \(22 total points\) Linear Regression}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{\(3 points\) Describe the main properties of the data, focusing on the size, data ranges, and data types. }{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{\(3 points\) Fit a linear model to the data so that we can predict exam\137score from revision\137time. Report the estimated model parameters w. Describe what the parameters represent for this 1D data. For this part, you should use the sklearn implementation of Linear Regression. Hint: By default in sklearn fit\137intercept = True. Instead, set fit\137intercept = False and pre-pend 1 to each value of xi yourself to create bold0mu mumu \(xi\) = [1, xi]. \040}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{\(3 points\) Display the fitted linear model and the input data on the same plot. }{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{\(3 points\) Instead of using sklearn, implement the closed-form solution for fitting a linear regression model yourself using numpy array operations. Report your code in the answer box. It should only take a few lines \(i.e. <5\). Hint: Only report the relevant lines for estimating w e.g. we do not need to see the data loading code. You can write the code in the answer box directly or paste in an image of it. \040}{section.1}% 5
\BOOKMARK [2][-]{subsection.1.5}{\(3 points\) Mean Squared Error \(MSE\) is a common metric used for evaluating the performance of regression models. Write out the expression for MSE and list one of its limitations. \040Hint: For notation, you can use y for the ground truth quantity and \040\(\044\134hat\173y\175\044 in latex\) in place of the model prediction. }{section.1}% 6
\BOOKMARK [2][-]{subsection.1.6}{\(3 points\) Our next step will be to evaluate the performance of the fitted models using Mean Squared Error \(MSE\). Report the MSE of the data in regression\137part1.csv for your prediction of exam\137score. You should report the MSE for the linear model fitted using sklearn and the model resulting from your closed-form solution. Comment on any differences in their performance. }{section.1}% 7
\BOOKMARK [2][-]{subsection.1.7}{\(4 points\) Assume that the optimal value of w0 is 20, it is not but let's assume so for now. Create a plot where you vary w1 from -2 to +2 on the horizontal axis, and report the Mean Squared Error on the vertical axis for each setting of w = [w0, w1] across the dataset. Describe the resulting plot. Where is its minimum? Is this value to be expected? Hint: You can try 100 values of w1 i.e. w1 = np.linspace\(-2,2, 100\). }{section.1}% 8
\BOOKMARK [1][-]{section.2}{: \(18 total points\) Nonlinear Regression}{}% 9
\BOOKMARK [2][-]{subsection.2.1}{\(5 points\) Fit four different polynomial regression models to the data by varying the degree of polynomial features used i.e. M = 1 to 4. For example, M=3 means that bold0mu mumu \(xi\) = [1, xi, xi2, xi3]. Plot the resulting models on the same plot and also include the input data. Hint: \040You can again use the sklearn implementation of Linear Regression and you can also use PolynomialFeatures to generate the polynomial features. Again, set fit\137intercept = False. }{section.2}% 10
\BOOKMARK [2][-]{subsection.2.2}{\(3 points\) Create a bar plot where you display the Mean Squared Error of each of the four different polynomial regression models from the previous question.}{section.2}% 11
\BOOKMARK [2][-]{subsection.2.3}{\(4 points\) Comment on the fit and Mean Squared Error values of the M=3 and M=4 polynomial regression models. Do they result in the same or different performance? Based on these results, which model would you choose?}{section.2}% 12
\BOOKMARK [2][-]{subsection.2.4}{\(6 points\) Instead of using polynomial basis functions, in this final part we will use another type of basis function - radial basis functions \(RBF\). Specifically, we will define bold0mu mumu \(xi\) = [1, rbf\(xi; c1, \), rbf\(xi; c2, \), rbf\(xi; c3, \), rbf\(xi; c4, \)], where rbf\(x; c, \) = exp\(-0.5\(x-c\)2 / 2\) is an RBF kernel with center c and width . Note that in this example, we are using the same width \040for each RBF, but different centers for each. Let c1=-4.0, c2=-2.0, c3=2.0, and c4=4.0 and plot the resulting nonlinear predictions using the regression\137part2.csv dataset for \1730.2, 100, 1000\175. You can plot all three results on the same figure. Comment on the impact of larger or smaller values of . }{section.2}% 13
\BOOKMARK [1][-]{section.3}{: \(26 total points\) Decision Trees}{}% 14
\BOOKMARK [2][-]{subsection.3.1}{\(4 points\) Load the data, taking care to separate the target binary class label we want to predict, smiling, from the input attributes. Summarise the main properties of both the training and test splits. }{section.3}% 15
\BOOKMARK [2][-]{subsection.3.2}{\(4 points\) Even though the input attributes are high dimensional, they actually consist of a set of 2D coordinates representing points on the faces of each person in the dataset. Create a scatter plot of the average location for each 2D coordinate. One for \(i\) smiling and \(ii\) one not smiling faces. For instance, in the case of smiling faces, you would average each of the rows where smiling = 1. You can plot both on the same figure, but use different colors for each of the two cases. Comment on any difference you notice between the two sets of points. \040Hint: Your plot should contain two faces. }{section.3}% 16
\BOOKMARK [2][-]{subsection.3.3}{\(2 points\) There are different measures that can be used in decision trees when evaluating the quality of a split. What measure of purity at a node does the DecisionTreeClassifier in sklearn use for classification by default? What is the advantage, if any, of using this measure compared to entropy? }{section.3}% 17
\BOOKMARK [2][-]{subsection.3.4}{\(3 points\) One of the hyper-parameters of a decision tree classifier is the maximum depth of the tree. What impact does smaller or larger values of this parameter have? Give one potential problem for small values and two for large values. }{section.3}% 18
\BOOKMARK [2][-]{subsection.3.5}{\(6 points\) Train three different decision tree classifiers with a maximum depth of 2, 8, and 20 respectively. Report the maximum depth, the training accuracy \(in \045\), and the test accuracy \(in \045\) for each of the three trees. Comment on which model is best and why it is best. \040Hint: Set random\137state = 2001 and use the predict\(\) method of the DecisionTreeClassifier so that you do not need to set a threshold on the output predictions. You can set the maximum depth of the decision tree using the max\137depth hyper-parameter. }{section.3}% 19
\BOOKMARK [2][-]{subsection.3.6}{\(5 points\) Report the names of the top three most important attributes, in order of importance, according to the Gini importance from DecisionTreeClassifier. Does the one with the highest importance make sense in the context of this classification task? \040Hint: Use the trained model with max\137depth = 8 and again set random\137state = 2001. }{section.3}% 20
\BOOKMARK [2][-]{subsection.3.7}{\(2 points\) Are there any limitations of the current choice of input attributes used i.e. 2D point locations? If so, name one. }{section.3}% 21
\BOOKMARK [1][-]{section.4}{: \(14 total points\) Evaluating Binary Classifiers}{}% 22
\BOOKMARK [2][-]{subsection.4.1}{\(4 points\) Report the classification accuracy \(in \045\) for each of the four different models using the gt attribute as the ground truth class labels. Use a threshold of >= 0.5 to convert the continuous classifier outputs into binary predictions. Which model is the best according to this metric? What, if any, are the limitations of the above method for computing accuracy and how would you improve it without changing the metric used? }{section.4}% 23
\BOOKMARK [2][-]{subsection.4.2}{\(4 points\) Instead of using classification accuracy, report the Area Under the ROC Curve \(AUC\) for each model. Does the model with the best AUC also have the best accuracy? If not, why not? Hint: You can use the roc\137auc\137score function from sklearn. }{section.4}% 24
\BOOKMARK [2][-]{subsection.4.3}{\(6 points\) Plot ROC curves for each of the four models on the same plot. Comment on the ROC curve for alg\1373? Is there anything that can be done to improve the performance of alg\1373 without having to retrain the model? Hint: You can use the roc\137curve function from sklearn. }{section.4}% 25
